{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Random forest classifier for MNIST</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i hope n=10 to predict 0..9 might work\n",
    "sk=RandomForestClassifier(n_estimators=10,criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "done\n",
      "[7 3 4 ..., 5 6 8]\n",
      "done\n",
      "[7 2 1 ..., 4 5 6]\n",
      "train_x, (10000, 784)\n",
      "train_y, (10000,)\n",
      "test_x, (1000, 784)\n",
      "test_y, (1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print mnist.train.images.shape\n",
    "print mnist.train.labels.shape\n",
    "print type(mnist.train.images)\n",
    "print type(mnist.train.labels)\n",
    "\n",
    "\n",
    "yl=[]\n",
    "for g in mnist.train.labels:\n",
    "    l=list(g)\n",
    "    yl.append(l.index(1))\n",
    "print \"done\"    \n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "label=numpy.array(yl)\n",
    "print label\n",
    "\n",
    "\n",
    "testing=[]\n",
    "for g in mnist.test.labels:\n",
    "    l=list(g)\n",
    "    testing.append(l.index(1))\n",
    "print \"done\"\n",
    "\n",
    "testlabel=numpy.array(testing)\n",
    "print testlabel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x=mnist.train.images[:10000]\n",
    "train_y=label[:10000]\n",
    "test_x=mnist.test.images[:1000]\n",
    "test_y=testlabel[:1000]\n",
    "#print type(mnist.train)\n",
    "print \"train_x,\",train_x.shape\n",
    "print \"train_y,\",train_y.shape\n",
    "print \"test_x,\",test_x.shape\n",
    "print \"test_y,\",test_y.shape \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sk.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 3 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 3 4 6 4 3 0 7 0 2 8\n",
      " 1 7 3 7 9 7 7 6 2 7 8 4 7 5 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 9 4 4 9 2 3 8 7 6 4 4 0 5 8 5 6 6 5 2 8 1 0 1 6 4 6 7 2 1 9 1 8 2\n",
      " 0 2 9 0 5 5 1 5 6 0 2 4 4 6 5 4 6 5 4 2 1 4 4 7 3 3 2 7 1 8 1 8 1 8 5 0 8\n",
      " 4 2 5 0 1 1 1 0 9 0 3 1 6 4 2 3 6 1 1 1 3 9 5 2 4 4 5 9 3 9 0 3 5 5 5 7 2\n",
      " 2 7 1 2 8 4 1 7 3 3 8 9 7 9 2 2 4 1 5 5 8 7 2 5 0 4 4 2 4 1 9 5 7 7 2 8 2\n",
      " 0 8 5 7 7 3 1 8 1 0 0 3 0 1 9 9 4 1 8 2 1 2 9 7 5 9 2 6 4 1 5 5 2 9 2 0 4\n",
      " 0 0 2 8 1 7 1 7 4 0 2 7 4 3 3 0 0 5 1 9 6 5 3 5 7 7 9 3 7 6 2 0 7 1 1 2 1\n",
      " 5 3 3 9 7 8 6 3 4 1 3 8 1 0 5 1 3 1 5 5 6 1 8 5 1 7 4 4 6 3 2 5 0 4 5 6 3\n",
      " 7 2 0 8 8 5 9 1 1 4 0 7 3 7 6 1 6 2 1 9 2 8 6 1 9 5 2 5 4 4 2 8 3 9 2 4 0\n",
      " 0 3 1 7 7 3 7 9 7 1 9 2 1 4 2 9 2 0 4 9 1 4 8 1 8 4 4 9 8 8 3 7 6 0 0 3 0\n",
      " 2 6 6 4 8 5 3 3 2 3 9 1 2 3 8 0 5 6 6 6 3 8 8 2 7 5 8 9 6 1 8 4 1 2 5 8 1\n",
      " 9 7 8 4 0 4 9 9 1 0 5 2 3 7 0 9 8 0 6 3 9 2 2 1 3 1 5 5 5 7 4 2 2 6 3 2 6\n",
      " 5 4 8 9 7 1 5 0 3 8 3 1 4 3 4 4 6 4 2 1 8 2 5 4 1 4 4 0 0 2 3 2 7 2 0 6 7\n",
      " 4 4 7 9 6 9 2 9 8 0 9 6 0 6 3 5 9 8 3 3 9 3 3 7 7 8 0 2 2 1 7 0 6 5 4 3 8\n",
      " 0 9 6 3 8 0 9 9 6 8 6 8 5 7 8 6 0 2 2 0 2 2 3 1 9 7 5 8 0 8 4 6 2 6 7 8 9\n",
      " 2 9 8 2 2 9 2 7 2 5 9 1 8 0 2 0 5 2 1 3 7 6 7 1 2 0 3 0 3 7 8 4 0 9 1 5 6\n",
      " 7 1 4 3 4 9 1 9 5 1 7 3 9 7 6 9 1 3 2 8 3 3 6 9 2 9 5 8 8 1 1 4 4 3 1 0 7\n",
      " 7 0 7 9 4 4 8 5 5 4 0 5 2 1 6 8 4 8 0 4 0 6 1 7 3 2 6 7 2 6 9 3 1 4 6 2 5\n",
      " 9 2 0 6 2 1 7 3 4 1 0 5 4 3 1 1 7 4 9 9 9 8 4 0 2 4 5 1 1 6 4 7 1 9 4 2 4\n",
      " 1 5 5 3 8 3 1 4 5 6 2 9 4 1 5 3 8 0 3 2 5 1 2 8 3 4 4 0 8 8 3 3 1 2 3 5 9\n",
      " 6 3 2 0 1 3 6 0 7 2 1 7 1 4 2 4 4 1 7 9 6 1 1 2 4 3 1 7 7 4 7 0 7 3 1 3 1\n",
      " 0 7 7 0 3 5 5 2 7 6 6 9 2 8 3 5 2 2 5 6 0 8 2 9 2 8 3 8 8 7 9 9 3 0 6 6 3\n",
      " 2 1 3 2 2 9 8 0 0 5 3 8 3 4 4 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 2 1 2 2 3 7\n",
      " 3 8 3 9 1 7 4 0 3 5 5 8 6 3 2 6 7 6 6 3 2 7 9 1 1 7 5 4 4 9 5 1 3 6 4 7 8\n",
      " 7 1 1 0 9 1 4 4 5 4 0 6 2 2 3 1 5 1 2 0 2 8 1 2 6 7 1 6 2 3 9 0 1 2 2 0 8\n",
      " 9]\n"
     ]
    }
   ],
   "source": [
    "predForest = sk.predict(test_x)\n",
    "print predForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892\n"
     ]
    }
   ],
   "source": [
    "print sk.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForests's Accuracy:  0.892\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"RandomForests's Accuracy: \"), metrics.accuracy_score(test_y, predForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=610059849, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=2073005936, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=21920608, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=200495314, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=1982503366, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=1215269749, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=1073481039, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=1699902174, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=430279205, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=90362916, splitter='best')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.estimators_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
